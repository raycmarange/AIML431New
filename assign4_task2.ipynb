{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raycmarange/AIML431New/blob/main/assign4_task2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df3c38f8",
      "metadata": {
        "id": "df3c38f8"
      },
      "outputs": [],
      "source": [
        "# assign4-task2.ipynb\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module='tqdm.auto')\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module='sklearn')\n",
        "warnings.filterwarnings(\"ignore\", category=SyntaxWarning)\n",
        "\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import re\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from transformers import (\n",
        "    BertTokenizer, BertForSequenceClassification,\n",
        "    DistilBertTokenizer, DistilBertForSequenceClassification,\n",
        "    get_linear_schedule_with_warmup\n",
        ")\n",
        "from torch.optim import AdamW\n",
        "from torch.utils.data import DataLoader, TensorDataset, RandomSampler, SequentialSampler\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import PCA\n",
        "import seaborn as sns\n",
        "import torch.nn as nn\n",
        "from tqdm.auto import tqdm  # Enhanced progress bars\n",
        "from imblearn.over_sampling import RandomOverSampler  # Added for oversampling\n",
        "\n",
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "def balance_dataset(texts, labels):\n",
        "    \"\"\"Add oversampling for minority class\"\"\"\n",
        "    print(\"Applying RandomOverSampler to balance the dataset...\")\n",
        "    print(f\"Original class distribution: {np.unique(labels, return_counts=True)}\")\n",
        "\n",
        "    ros = RandomOverSampler(random_state=42)\n",
        "    texts_reshaped = np.array(texts).reshape(-1, 1)\n",
        "    texts_resampled, labels_resampled = ros.fit_resample(texts_reshaped, labels)\n",
        "\n",
        "    print(f\"After oversampling: {np.unique(labels_resampled, return_counts=True)}\")\n",
        "    return texts_resampled.flatten(), labels_resampled\n",
        "\n",
        "# Enhanced preprocessing functions\n",
        "def enhanced_text_preprocessing(text):\n",
        "    \"\"\"Apply additional text preprocessing steps\"\"\"\n",
        "    if pd.isna(text):\n",
        "        return \"\"\n",
        "\n",
        "    text = str(text)\n",
        "\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove excessive whitespace\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    # Remove special characters but keep basic punctuation\n",
        "    text = re.sub(r'[^\\w\\s\\.\\,\\!\\?]', '', text)\n",
        "\n",
        "    # Normalize URLs and numbers (optional - can help with generalization)\n",
        "    text = re.sub(r'http\\S+', '[URL]', text)\n",
        "    text = re.sub(r'www\\.\\S+', '[URL]', text)\n",
        "    text = re.sub(r'\\d+', '[NUM]', text)\n",
        "\n",
        "    return text\n",
        "\n",
        "def load_and_preprocess_data_enhanced(file_path, apply_preprocessing=True):\n",
        "    \"\"\"Enhanced data loading with preprocessing options\"\"\"\n",
        "    try:\n",
        "        df = pd.read_csv(file_path, delimiter='\\t', header=None, names=['label', 'text'], encoding='utf-8')\n",
        "        print(\"Successfully loaded with tab delimiter\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error with tab delimiter: {e}\")\n",
        "        try:\n",
        "            df = pd.read_csv(file_path, delimiter=',', header=None, names=['label', 'text'], encoding='utf-8')\n",
        "            print(\"Successfully loaded with comma delimiter\")\n",
        "        except Exception as e2:\n",
        "            print(f\"Error with comma delimiter: {e2}\")\n",
        "            # Manual parsing as fallback\n",
        "            print(\"Attempting manual file reading...\")\n",
        "            try:\n",
        "                with open(file_path, 'r', encoding='utf-8') as f:\n",
        "                    lines = f.readlines()\n",
        "\n",
        "                data = []\n",
        "                for line in lines:\n",
        "                    parts = line.strip().split('\\t', 1)\n",
        "                    if len(parts) == 2:\n",
        "                        data.append(parts)\n",
        "                    else:\n",
        "                        parts = line.strip().split(' ', 1)\n",
        "                        if len(parts) == 2:\n",
        "                            data.append(parts)\n",
        "\n",
        "                df = pd.DataFrame(data, columns=['label', 'text'])\n",
        "                print(\"Successfully loaded with manual parsing\")\n",
        "            except Exception as e3:\n",
        "                print(f\"All loading methods failed: {e3}\")\n",
        "                return None\n",
        "\n",
        "    if df is None or len(df) == 0:\n",
        "        print(\"Failed to load any data\")\n",
        "        return None\n",
        "\n",
        "    print(f\"Dataset loaded: {len(df)} samples\")\n",
        "    print(f\"Original label distribution:\")\n",
        "    print(df['label'].value_counts())\n",
        "\n",
        "    # Enhanced preprocessing\n",
        "    if apply_preprocessing:\n",
        "        print(\"Applying enhanced text preprocessing...\")\n",
        "        # Use tqdm for preprocessing progress\n",
        "        tqdm.pandas(desc=\"Preprocessing texts\")\n",
        "        df['text_clean'] = df['text'].progress_apply(enhanced_text_preprocessing)\n",
        "        # Remove empty texts after cleaning\n",
        "        df = df[df['text_clean'].str.len() > 0]\n",
        "        print(f\"After cleaning: {len(df)} samples\")\n",
        "\n",
        "    # Convert labels to binary\n",
        "    df['label'] = df['label'].map({'ham': 0, 'spam': 1})\n",
        "\n",
        "    # Check for missing values\n",
        "    print(f\"Missing values: {df.isnull().sum()}\")\n",
        "    df = df.dropna()\n",
        "\n",
        "    return df\n",
        "\n",
        "def create_sample_dataset():\n",
        "    \"\"\"Create sample dataset for testing\"\"\"\n",
        "    print(\"Creating sample dataset...\")\n",
        "\n",
        "    ham_samples = [\n",
        "        \"Ok lar... Joking wif u oni...\",\n",
        "        \"U dun say so early hor... U c already then say...\",\n",
        "        \"Nah I don't think he goes to usf, he lives around here though\",\n",
        "        \"Hey, are we still meeting for lunch tomorrow?\",\n",
        "        \"Can you pick up milk on your way home?\",\n",
        "    ]\n",
        "\n",
        "    spam_samples = [\n",
        "        \"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\",\n",
        "        \"FreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, Â£1.50 to rcv\",\n",
        "        \"WINNER!! As a valued network customer you have been selected to receive a Â£900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.\",\n",
        "        \"Urgent! You have won a 1 week FREE membership in our Â£100,000 Prize Jackpot! Txt the word: CLAIM to No: 81010 T&C www.dbuk.net 16+\",\n",
        "        \"Congratulations! You've been selected for a free iPhone. Click here to claim: http://bit.ly/freeiphone\",\n",
        "    ]\n",
        "\n",
        "    sample_texts = ham_samples + spam_samples\n",
        "    sample_labels = [0] * len(ham_samples) + [1] * len(spam_samples)\n",
        "\n",
        "    return sample_texts, sample_labels\n",
        "\n",
        "# CNN classifier for BERT embeddings\n",
        "class CNNClassifier(nn.Module):\n",
        "    def __init__(self, bert_model, hidden_size=768, num_filters=100, filter_sizes=[3,4,5], num_classes=2, dropout=0.3):\n",
        "        super(CNNClassifier, self).__init__()\n",
        "        self.bert = bert_model\n",
        "        self.convs = nn.ModuleList([\n",
        "            nn.Conv1d(hidden_size, num_filters, fs) for fs in filter_sizes\n",
        "        ])\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.classifier = nn.Linear(num_filters * len(filter_sizes), num_classes)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, labels=None):\n",
        "        # Get BERT outputs\n",
        "        outputs = self.bert.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        hidden_states = outputs.last_hidden_state  # [batch_size, seq_len, hidden_size]\n",
        "\n",
        "        # Apply CNN on the sequence dimension (transpose for Conv1d)\n",
        "        x = hidden_states.transpose(1, 2)  # [batch_size, hidden_size, seq_len]\n",
        "\n",
        "        conv_outputs = []\n",
        "        for conv in self.convs:\n",
        "            conv_out = torch.relu(conv(x))  # [batch_size, num_filters, seq_len - filter_size + 1]\n",
        "            pooled = torch.max(conv_out, dim=2)[0]  # [batch_size, num_filters]\n",
        "            conv_outputs.append(pooled)\n",
        "\n",
        "        # Concatenate CNN outputs\n",
        "        cnn_features = torch.cat(conv_outputs, dim=1)  # [batch_size, num_filters * len(filter_sizes)]\n",
        "\n",
        "        # Classification\n",
        "        logits = self.classifier(self.dropout(cnn_features))\n",
        "\n",
        "        if labels is not None:\n",
        "            loss_fct = nn.CrossEntropyLoss()\n",
        "            loss = loss_fct(logits, labels)\n",
        "            return loss, logits\n",
        "        return logits\n",
        "\n",
        "def run_bert_experiment(train_texts, train_labels, test_texts, test_labels,\n",
        "                       model_type='bert', use_cls=True, use_cnn=False, experiment_name=\"Experiment\",\n",
        "                       apply_oversampling=True):  # Added oversampling parameter\n",
        "    \"\"\"Run a single BERT experiment with given parameters\"\"\"\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    print(f\"\\nðŸš€ Starting {experiment_name}...\")\n",
        "    print(f\"Training samples: {len(train_texts)}, Test samples: {len(test_texts)}\")\n",
        "\n",
        "    # Apply oversampling if requested\n",
        "    if apply_oversampling and len(np.unique(train_labels)) > 1:\n",
        "        train_texts, train_labels = balance_dataset(train_texts, train_labels)\n",
        "        print(f\"After oversampling - Training samples: {len(train_texts)}\")\n",
        "\n",
        "    # Select tokenizer and model\n",
        "    if model_type == 'distilbert':\n",
        "        print(\"Loading DistilBERT tokenizer and model...\")\n",
        "        tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "        base_model = DistilBertForSequenceClassification.from_pretrained(\n",
        "            'distilbert-base-uncased', num_labels=2, output_hidden_states=True\n",
        "        )\n",
        "    else:\n",
        "        print(\"Loading BERT tokenizer and model...\")\n",
        "        tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "        base_model = BertForSequenceClassification.from_pretrained(\n",
        "            'bert-base-uncased', num_labels=2, output_hidden_states=True\n",
        "        )\n",
        "\n",
        "    # Tokenize data with progress indication\n",
        "    def tokenize_data(texts, labels, max_length=128):\n",
        "        print(f\"Tokenizing {len(texts)} texts...\")\n",
        "        if hasattr(texts, 'tolist'):\n",
        "            texts = texts.tolist()\n",
        "        elif hasattr(texts, 'values'):\n",
        "            texts = texts.values.tolist()\n",
        "\n",
        "        # Show progress for tokenization\n",
        "        encoded_data = tokenizer(\n",
        "            texts,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            max_length=max_length,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        input_ids = encoded_data['input_ids']\n",
        "        attention_masks = encoded_data['attention_mask']\n",
        "        labels_tensor = torch.tensor(labels)\n",
        "        print(\"âœ“ Tokenization completed\")\n",
        "        return input_ids, attention_masks, labels_tensor\n",
        "\n",
        "    train_input_ids, train_attention_masks, train_labels_tensor = tokenize_data(train_texts, train_labels)\n",
        "    test_input_ids, test_attention_masks, test_labels_tensor = tokenize_data(test_texts, test_labels)\n",
        "\n",
        "    # Create DataLoaders\n",
        "    batch_size = min(16, len(train_texts))\n",
        "    train_dataset = TensorDataset(train_input_ids, train_attention_masks, train_labels_tensor)\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    test_dataset = TensorDataset(test_input_ids, test_attention_masks, test_labels_tensor)\n",
        "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "    print(f\"Batch size: {batch_size}, Total batches: {len(train_dataloader)}\")\n",
        "\n",
        "    # Select model architecture\n",
        "    if use_cnn and model_type == 'bert':\n",
        "        model = CNNClassifier(base_model)\n",
        "        print(\"Using CNN classifier on BERT embeddings\")\n",
        "    else:\n",
        "        model = base_model\n",
        "        print(\"Using standard classifier head\")\n",
        "\n",
        "    model.to(device)\n",
        "    print(f\"Model moved to {device}\")\n",
        "\n",
        "    # Training setup\n",
        "    epochs = 2\n",
        "    optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "    total_steps = len(train_dataloader) * epochs\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
        "\n",
        "    # Compute class weights for imbalanced data (even with oversampling, weights can help)\n",
        "    if len(np.unique(train_labels)) > 1:\n",
        "        class_weights = compute_class_weight('balanced', classes=np.unique(train_labels), y=train_labels)\n",
        "        class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
        "        print(f\"Class weights computed: {class_weights.cpu().numpy()}\")\n",
        "    else:\n",
        "        class_weights = None\n",
        "        print(\"Single class detected, no class weights applied\")\n",
        "\n",
        "    # Enhanced training loop with progress bars and status checks\n",
        "    print(f\"\\nðŸ“Š Starting training for {epochs} epochs...\")\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"\\nðŸŽ¯ Epoch {epoch+1}/{epochs} started at {time.strftime('%H:%M:%S')}\")\n",
        "        total_loss = 0\n",
        "        batch_times = []\n",
        "\n",
        "        # Create progress bar for batches\n",
        "        progress_bar = tqdm(train_dataloader, desc=f\"Epoch {epoch+1}/{epochs}\",\n",
        "                           unit=\"batch\", leave=True, position=0)\n",
        "\n",
        "        for batch_num, batch in enumerate(progress_bar):\n",
        "            batch_start_time = time.time()\n",
        "\n",
        "            b_input_ids, b_attention_mask, b_labels = [t.to(device) for t in batch]\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            if use_cnn:\n",
        "                loss, logits = model(b_input_ids, b_attention_mask, b_labels)\n",
        "            else:\n",
        "                outputs = model(b_input_ids, attention_mask=b_attention_mask, labels=b_labels)\n",
        "                loss = outputs.loss\n",
        "\n",
        "            # Apply class weights if available and not using CNN\n",
        "            if class_weights is not None and not use_cnn:\n",
        "                loss = (loss * class_weights[b_labels]).mean()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            # Calculate batch time and update progress bar\n",
        "            batch_time = time.time() - batch_start_time\n",
        "            batch_times.append(batch_time)\n",
        "            avg_batch_time = np.mean(batch_times[-10:])  # Average of last 10 batches\n",
        "\n",
        "            # Update progress bar description\n",
        "            progress_bar.set_postfix({\n",
        "                'loss': f'{loss.item():.4f}',\n",
        "                'avg_batch_time': f'{avg_batch_time:.2f}s'\n",
        "            })\n",
        "\n",
        "            # Print status every 10 batches\n",
        "            if batch_num % 10 == 0:\n",
        "                print(f\"   Batch {batch_num}/{len(train_dataloader)} - Loss: {loss.item():.4f}\")\n",
        "\n",
        "        # Epoch completion\n",
        "        avg_loss = total_loss / len(train_dataloader)\n",
        "        epoch_time = time.time() - start_time\n",
        "        print(f\"âœ… Epoch {epoch+1}/{epochs} completed at {time.strftime('%H:%M:%S')}\")\n",
        "        print(f\"   Average Loss: {avg_loss:.4f}\")\n",
        "        print(f\"   Epoch Time: {epoch_time:.2f}s\")\n",
        "        print(f\"   Still running... Preparing next epoch\" if epoch < epochs - 1 else \"   Training completed!\")\n",
        "\n",
        "    # Enhanced evaluation with progress indication\n",
        "    print(f\"\\nðŸ“ˆ Starting evaluation...\")\n",
        "    model.eval()\n",
        "    predictions, true_labels = [], []\n",
        "\n",
        "    eval_progress = tqdm(test_dataloader, desc=\"Evaluating\", unit=\"batch\")\n",
        "\n",
        "    for batch in eval_progress:\n",
        "        b_input_ids, b_attention_mask, b_labels = [t.to(device) for t in batch]\n",
        "\n",
        "        with torch.no_grad():\n",
        "            if use_cnn:\n",
        "                logits = model(b_input_ids, b_attention_mask)\n",
        "            else:\n",
        "                outputs = model(b_input_ids, attention_mask=b_attention_mask)\n",
        "                logits = outputs.logits\n",
        "\n",
        "        preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
        "        predictions.extend(preds)\n",
        "        true_labels.extend(b_labels.cpu().numpy())\n",
        "\n",
        "    print(\"âœ“ Evaluation completed\")\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(true_labels, predictions)\n",
        "    if len(np.unique(true_labels)) > 1:\n",
        "        f1 = f1_score(true_labels, predictions, average='weighted')\n",
        "    else:\n",
        "        f1 = 1.0 if accuracy == 1.0 else 0.0\n",
        "\n",
        "    total_time = time.time() - start_time\n",
        "\n",
        "    print(f\"\\nðŸŽ‰ {experiment_name} Results:\")\n",
        "    print(f\"   Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"   F1-Score: {f1:.4f}\")\n",
        "    print(f\"   Total Time: {total_time:.2f}s\")\n",
        "\n",
        "    if len(np.unique(true_labels)) > 1:\n",
        "        print(\"   Classification Report:\")\n",
        "        print(classification_report(true_labels, predictions, target_names=['ham', 'spam']))\n",
        "    else:\n",
        "        print(\"   Only one class present in test set\")\n",
        "\n",
        "    return {\n",
        "        'name': experiment_name,\n",
        "        'accuracy': accuracy,\n",
        "        'f1_score': f1,\n",
        "        'training_time': total_time,\n",
        "        'predictions': predictions,\n",
        "        'true_labels': true_labels\n",
        "    }\n",
        "\n",
        "def plot_comparison(results):\n",
        "    \"\"\"Plot comparison of different experiments\"\"\"\n",
        "    if not results:\n",
        "        print(\"No results to plot\")\n",
        "        return\n",
        "\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    # Accuracy comparison\n",
        "    names = [results[exp]['name'] for exp in results]\n",
        "    accuracies = [results[exp]['accuracy'] for exp in results]\n",
        "\n",
        "    bars1 = axes[0].bar(names, accuracies, color=['skyblue', 'lightcoral', 'lightgreen'])\n",
        "    axes[0].set_title('Accuracy Comparison')\n",
        "    axes[0].set_ylabel('Accuracy')\n",
        "    axes[0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "    # Add value labels on bars\n",
        "    for bar in bars1:\n",
        "        height = bar.get_height()\n",
        "        axes[0].text(bar.get_x() + bar.get_width()/2., height,\n",
        "                    f'{height:.3f}', ha='center', va='bottom')\n",
        "\n",
        "    # F1-score comparison\n",
        "    f1_scores = [results[exp]['f1_score'] for exp in results]\n",
        "    bars2 = axes[1].bar(names, f1_scores, color=['skyblue', 'lightcoral', 'lightgreen'])\n",
        "    axes[1].set_title('F1-Score Comparison')\n",
        "    axes[1].set_ylabel('F1-Score')\n",
        "    axes[1].tick_params(axis='x', rotation=45)\n",
        "\n",
        "    for bar in bars2:\n",
        "        height = bar.get_height()\n",
        "        axes[1].text(bar.get_x() + bar.get_width()/2., height,\n",
        "                    f'{height:.3f}', ha='center', va='bottom')\n",
        "\n",
        "    # Training time comparison\n",
        "    times = [results[exp]['training_time'] for exp in results]\n",
        "    bars3 = axes[2].bar(names, times, color=['skyblue', 'lightcoral', 'lightgreen'])\n",
        "    axes[2].set_title('Training Time Comparison')\n",
        "    axes[2].set_ylabel('Time (seconds)')\n",
        "    axes[2].tick_params(axis='x', rotation=45)\n",
        "\n",
        "    for bar in bars3:\n",
        "        height = bar.get_height()\n",
        "        axes[2].text(bar.get_x() + bar.get_width()/2., height,\n",
        "                    f'{height:.1f}s', ha='center', va='bottom')\n",
        "\n",
        "    # Confusion matrix for the best experiment\n",
        "    best_exp = max(results.keys(), key=lambda x: results[x]['accuracy'])\n",
        "    cm = confusion_matrix(results[best_exp]['true_labels'], results[best_exp]['predictions'])\n",
        "    sns.heatmap(cm, annot=True, fmt='d', ax=axes[3], cmap='Blues',\n",
        "               xticklabels=['ham', 'spam'], yticklabels=['ham', 'spam'])\n",
        "    axes[3].set_title(f'Best Model: {results[best_exp][\"name\"]}\\nConfusion Matrix')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Main execution function\n",
        "def run_task2_experiments():\n",
        "    \"\"\"Run different experiments for Task 2\"\"\"\n",
        "\n",
        "    # Get the current directory\n",
        "    current_dir = os.getcwd()\n",
        "\n",
        "    # Try different possible file paths\n",
        "    possible_paths = [\n",
        "        \"SMSSpamCollection\", \"./SMSSpamCollection\", \"SMSSpamCollection.txt\",\n",
        "        \"./SMSSpamCollection.txt\", os.path.join(current_dir, \"SMSSpamCollection\"),\n",
        "        os.path.join(current_dir, \"SMSSpamCollection.txt\"),\n",
        "    ]\n",
        "\n",
        "    file_path = None\n",
        "    for path in possible_paths:\n",
        "        if os.path.exists(path):\n",
        "            file_path = path\n",
        "            print(f\"Found file at: {path}\")\n",
        "            break\n",
        "\n",
        "    if file_path is None:\n",
        "        print(\"SMSSpamCollection file not found. Using sample dataset.\")\n",
        "        sample_texts, sample_labels = create_sample_dataset()\n",
        "        df = pd.DataFrame({'text': sample_texts, 'label': sample_labels})\n",
        "        df['text_clean'] = df['text']\n",
        "    else:\n",
        "        # Load with enhanced preprocessing\n",
        "        df = load_and_preprocess_data_enhanced(file_path, apply_preprocessing=True)\n",
        "        if df is None or len(df) == 0:\n",
        "            print(\"Failed to load dataset, using sample data instead\")\n",
        "            sample_texts, sample_labels = create_sample_dataset()\n",
        "            df = pd.DataFrame({'text': sample_texts, 'label': sample_labels})\n",
        "            df['text_clean'] = df['text']\n",
        "\n",
        "    print(f\"Final dataset size: {len(df)}\")\n",
        "    print(f\"Class distribution: {df['label'].value_counts().to_dict()}\")\n",
        "\n",
        "    # Use cleaned text if available\n",
        "    text_column = 'text_clean' if 'text_clean' in df.columns else 'text'\n",
        "\n",
        "    # Split data\n",
        "    train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
        "        df[text_column].values, df['label'].values, test_size=0.2, random_state=42, stratify=df['label']\n",
        "    )\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    # Experiment 1: Base BERT with enhanced preprocessing and oversampling\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"EXPERIMENT 1: Base BERT with Enhanced Preprocessing + Oversampling\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    results['exp1'] = run_bert_experiment(\n",
        "        train_texts, train_labels, test_texts, test_labels,\n",
        "        model_type='bert', use_cls=True, use_cnn=False,\n",
        "        experiment_name=\"Base BERT + Preprocessing + Oversampling\",\n",
        "        apply_oversampling=True\n",
        "    )\n",
        "\n",
        "    # Experiment 2: BERT with CNN classifier and oversampling\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"EXPERIMENT 2: BERT with CNN Classifier + Oversampling\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    results['exp2'] = run_bert_experiment(\n",
        "        train_texts, train_labels, test_texts, test_labels,\n",
        "        model_type='bert', use_cls=False, use_cnn=True,\n",
        "        experiment_name=\"BERT + CNN + Oversampling\",\n",
        "        apply_oversampling=True\n",
        "    )\n",
        "\n",
        "    # Experiment 3: DistilBERT with oversampling\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"EXPERIMENT 3: DistilBERT + Oversampling\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    results['exp3'] = run_bert_experiment(\n",
        "        train_texts, train_labels, test_texts, test_labels,\n",
        "        model_type='distilbert', use_cls=True, use_cnn=False,\n",
        "        experiment_name=\"DistilBERT + Oversampling\",\n",
        "        apply_oversampling=True\n",
        "    )\n",
        "\n",
        "    # Compare results\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"COMPARISON OF ALL EXPERIMENTS\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    comparison_data = []\n",
        "    for exp_key in results:\n",
        "        exp = results[exp_key]\n",
        "        comparison_data.append({\n",
        "            'Experiment': exp['name'],\n",
        "            'Accuracy': f\"{exp['accuracy']:.4f}\",\n",
        "            'F1-Score': f\"{exp['f1_score']:.4f}\",\n",
        "            'Training Time (s)': f\"{exp['training_time']:.2f}\"\n",
        "        })\n",
        "\n",
        "    comparison_df = pd.DataFrame(comparison_data)\n",
        "    print(comparison_df)\n",
        "\n",
        "    # Visualization\n",
        "    plot_comparison(results)\n",
        "\n",
        "    return results, comparison_df\n",
        "\n",
        "# Run the experiments\n",
        "print(\"Starting Task 2 experiments...\")\n",
        "results, comparison_df = run_task2_experiments()\n",
        "\n",
        "# Print summary\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TASK 2 SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "print(\"Experiments completed successfully!\")\n",
        "print(\"\\nKey improvements attempted in Task 2:\")\n",
        "print(\"1. Enhanced text preprocessing (cleaning, normalization)\")\n",
        "print(\"2. RandomOverSampler for dataset balancing\")\n",
        "print(\"3. CNN classifier on BERT embeddings (alternative to [CLS] token)\")\n",
        "print(\"4. DistilBERT model for efficiency\")\n",
        "print(\"5. Class weighting for handling imbalanced data\")\n",
        "print(\"6. Comprehensive evaluation and comparison\")\n",
        "\n",
        "# Save results for report\n",
        "comparison_df.to_csv('task2_results.csv', index=False)\n",
        "print(\"\\nResults saved to 'task2_results.csv'\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}